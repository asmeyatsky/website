steps:
  # Build the Next.js Website Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - 'gcr.io/$PROJECT_ID/website:$COMMIT_SHA'
      - '-t'
      - 'gcr.io/$PROJECT_ID/website:latest'
      - '.'

  # Push the Next.js Website Docker image to Google Container Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - 'gcr.io/$PROJECT_ID/website'

  # Build the AI News Scraper Docker image
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-f' # Specify Dockerfile name
      - 'Dockerfile.scraper'
      - '-t'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/ai-news-scraper-repo-us/ai-news-scraper:$COMMIT_SHA'
      - '-t'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/ai-news-scraper-repo-us/ai-news-scraper:latest'
      - '.' # Build context

  # Push the AI News Scraper Docker image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '--all-tags'
      - 'us-central1-docker.pkg.dev/$PROJECT_ID/ai-news-scraper-repo-us/ai-news-scraper'

  # Test GCS access before Next.js build
  - name: 'gcr.io/cloud-builders/gsutil'
    args: ['cat', 'gs://website-469906-ai-news/ai_news.json']
    id: 'test-gcs-access'

  # Deploy Next.js Website to Cloud Run
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'run'
      - 'deploy'
      - 'website'
      - '--image'
      - 'gcr.io/$PROJECT_ID/website:$COMMIT_SHA'
      - '--region'
      - 'europe-west1'
      - '--platform'
      - 'managed'
      - '--allow-unauthenticated'
      - '--port'
      - '3000'
      - '--memory'
      - '1Gi'
      - '--cpu'
      - '1'
      - '--max-instances'
      - '10'
      - '--set-startup-cpu-boost=true' # Ensure CPU boost is enabled
      - '--set-env-vars=PORT=3000' # Explicitly set PORT env var
      - '--set-env-vars=NODE_ENV=production' # Explicitly set NODE_ENV
      - '--set-env-vars=GOOGLE_CLOUD_PROJECT=website-469906' # Add project ID for GCS client
      - '--set-env-vars=GOOGLE_APPLICATION_CREDENTIALS=/var/run/secrets/kubernetes.io/serviceaccount/token' # Use default service account token
      - '--set-env-vars=GOOGLE_APPLICATION_CREDENTIALS_JSON_BASE64=' # Placeholder for key if needed
      - '--set-env-vars=GCS_BUCKET_NAME=website-469906-ai-news' # Pass bucket name as env var
      - '--set-env-vars=GCS_FILE_NAME=ai_news.json' # Pass file name as env var
      - '--set-env-vars=NEXT_PUBLIC_GCS_NEWS_JSON_URL=https://storage.googleapis.com/website-469906-ai-news/ai_news.json' # Public URL for client-side fetch
      - '--set-env-vars=CONTENTFUL_SPACE_ID=cxkmb6m0pcxc' # Contentful Space ID
      - '--set-env-vars=CONTENTFUL_ACCESS_TOKEN=wiC8MN-A3xfd1t5PBzKOhgg6Jn2TVX2CGcWe6de_j6o' # Contentful Access Token
      - '--set-timeout=600' # Increase timeout to 10 minutes

# Store images in Google Container Registry and Artifact Registry
images:
  - 'gcr.io/$PROJECT_ID/website:$COMMIT_SHA'
  - 'gcr.io/$PROJECT_ID/website:latest'
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/ai-news-scraper-repo-us/ai-news-scraper:$COMMIT_SHA'
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/ai-news-scraper-repo-us/ai-news-scraper:latest'

# Build options
options:
  machineType: 'E2_HIGHCPU_8'
  diskSizeGb: 100
  logging: CLOUD_LOGGING_ONLY

# Timeout for the entire build
timeout: 1200s
